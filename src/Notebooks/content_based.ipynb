{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5fe28c9-19b6-4cf3-9ee0-02a07448198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277301c2-9d9f-41a6-9df9-03a4a4419c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FILENAME = \"cleaned_content_based.csv\"\n",
    "DATA_PATH = os.getenv(\"FILES_LOCATION\")\n",
    "RECOMMENDER_TYPE = \"content_based\"\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, DATA_PATH, \"PNG\", RECOMMENDER_TYPE)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, extension=\"png\", resolution=300):  # Función para guardar las figuras que se vayan generando\n",
    "    img_path = os.path.join(IMAGES_PATH, fig_id + \".\" + extension)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(img_path, format=extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c872b4b4-ab11-4bb1-b323-9c6944e20de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Configuración de parámetros de matplotlib\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d560c7e0-e3cd-41cf-bd64-b236f52b522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"CSV\", FILENAME), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c0f87-dc93-4c09-a4ee-688679048bcf",
   "metadata": {},
   "source": [
    "# Content Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3644678-f46b-4c90-a48b-345a32e7d8c5",
   "metadata": {},
   "source": [
    "El primer modelo que hemos creado ha sido un recomendador muy simple, basado en las películas y su popularidad, con un filtro del género de la película. Sin embargo, este sistema recomienda las mismas películas a todos los usuarios, por lo que si un usuario quiere recomendaciones sobre películas de Romance, siempre recibirá las mismas recomendaciones que otros usuarios que busquen ese mismo género.\n",
    "\n",
    "En caso de que una persona quisiera conocer películas de un mismo director, actor o que tenga una trama similar a otra pero con diferentes géneros, el recomendador simple que hemos elaborado no serviría. Vamos a hacer dos tipos de recomendadores:\n",
    "\n",
    "- Basado en el contenido de la descripción de la película\n",
    "- Basado en los metadatos (director, actores, géneros...)\n",
    "\n",
    "De esta forma desarrollaremos dos sistemas de recomendación superiores al que hicimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a40a50-9edc-45a1-89d4-fb908fe9d8f4",
   "metadata": {},
   "source": [
    "## Basado en la descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bf10cc-6050-415f-a032-67c6db141883",
   "metadata": {},
   "source": [
    "Durante el procesamiento de los datos en _notebook_ EDA00, hicimos una característica que englobaba la reseña y el _tagline_ de las películas (en caso de haber _tagline_). A partir de esta descripción, podemos realizar un sistema de recomendación basado en la similaridad de las películas. Recordemos que en nuestro caso la característica que engloba todo se llama _**description**_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fddcb9a-3167-4483-9047-354fc457e782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>description</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>keywords</th>\n",
       "      <th>director</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['animation', 'comedy', 'family']</td>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>['tomhanks', 'timallen', 'donrickles']</td>\n",
       "      <td>['jealousi', 'toy', 'boy', 'friendship', 'frie...</td>\n",
       "      <td>['johnlasseter']</td>\n",
       "      <td>jealousi toy boy friendship friend rivalri boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['adventure', 'fantasy', 'family']</td>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>['robinwilliams', 'jonathanhyde', 'kirstendunst']</td>\n",
       "      <td>['boardgam', 'disappear', \"basedonchildren'sbo...</td>\n",
       "      <td>['joejohnston']</td>\n",
       "      <td>boardgam disappear basedonchildren'sbook newho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['romance', 'comedy']</td>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>['waltermatthau', 'jacklemmon', 'ann-margret']</td>\n",
       "      <td>['fish', 'bestfriend', 'duringcreditssting']</td>\n",
       "      <td>['howarddeutch']</td>\n",
       "      <td>fish bestfriend duringcreditssting waltermatth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               genres     id             title  \\\n",
       "0   ['animation', 'comedy', 'family']    862         Toy Story   \n",
       "1  ['adventure', 'fantasy', 'family']   8844           Jumanji   \n",
       "2               ['romance', 'comedy']  15602  Grumpier Old Men   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   \n",
       "1  When siblings Judy and Peter discover an encha...   \n",
       "2  A family wedding reignites the ancient feud be...   \n",
       "\n",
       "                                         description  popularity  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   21.946943   \n",
       "1  When siblings Judy and Peter discover an encha...   17.015539   \n",
       "2  A family wedding reignites the ancient feud be...   11.712900   \n",
       "\n",
       "   vote_average  vote_count  \\\n",
       "0           7.7      5415.0   \n",
       "1           6.9      2413.0   \n",
       "2           6.5        92.0   \n",
       "\n",
       "                                                cast  \\\n",
       "0             ['tomhanks', 'timallen', 'donrickles']   \n",
       "1  ['robinwilliams', 'jonathanhyde', 'kirstendunst']   \n",
       "2     ['waltermatthau', 'jacklemmon', 'ann-margret']   \n",
       "\n",
       "                                            keywords          director  \\\n",
       "0  ['jealousi', 'toy', 'boy', 'friendship', 'frie...  ['johnlasseter']   \n",
       "1  ['boardgam', 'disappear', \"basedonchildren'sbo...   ['joejohnston']   \n",
       "2       ['fish', 'bestfriend', 'duringcreditssting']  ['howarddeutch']   \n",
       "\n",
       "                                            metadata  \n",
       "0  jealousi toy boy friendship friend rivalri boy...  \n",
       "1  boardgam disappear basedonchildren'sbook newho...  \n",
       "2  fish bestfriend duringcreditssting waltermatth...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2aa73b-c75e-4da5-87a5-548d2e3a4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=\"metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f8695-65c3-46e6-8cfe-50f9b26092d0",
   "metadata": {},
   "source": [
    "Lo primero que vamos a realizar es una tokenización del texto, eliminando los _stopwords_ y después le vamos a pasar un _stemmer_ tras tokenizar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c3df50-8395-4c38-9f73-01932f357b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "stop_w = set(stopwords.words(\"english\"))  # Stopwords\n",
    "remove_non_alpha = lambda x: re.sub(r\"[^a-zA-Z]\", \" \", x)  # Elimina aquello que no sean palabras\n",
    "tokenize = lambda x: nltk.tokenize.word_tokenize(x)  # Tokeniza cada entrada\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmer_fn = lambda desc: \" \".join([stemmer.stem(w) for w in desc if w.lower() not in stop_w])  # Paso de estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a09494ed-1d04-43aa-b342-adda72e23fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in (remove_non_alpha, tokenize, stemmer_fn):\n",
    "    df[\"description\"] = df[\"description\"].transform(func=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61a58b8-98c6-4a72-9746-c2f0b037dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\", min_df=0.)  # Redundancia de stopwords\n",
    "tfidf_matrix = tfidf.fit_transform(df[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918a476c-8d3b-4685-ba8b-5b06e6d96f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41361, 921488)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad4bea-9f3d-4f5a-aa52-a4cbdbd42189",
   "metadata": {},
   "source": [
    "Como hemos utilizado _TfidfVectorizer_, vamos a computar la similaridad con el kernel lineal, ya que el producto interno nos dará como resultado la similaridad coseno. Utilizando el kernel lineal la computación será más rápida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be3c5a46-7cb7-4feb-90c0-8db35b838ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8918347a-ad38-4bbd-b6b2-a81825c0b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_mapper = pd.Series(df.index, index=df[\"title\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264cc5f7-180f-4263-9ba0-dd7fc57bf5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24813                              Avengers: Age of Ultron\n",
       "25223                          Tarzan's Greatest Adventure\n",
       "12143                                             Iron Man\n",
       "26054                                           Calculator\n",
       "14526                                           Iron Man 2\n",
       "28319                                    A Deadly Adoption\n",
       "19711                                           Iron Man 3\n",
       "30240                                                Hawks\n",
       "36118    Fittest On Earth (The Story Of The 2015 Reebok...\n",
       "17815                                                Verbo\n",
       "17113                  Behind Enemy Lines II: Axis of Evil\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = \"Avengers: Age of Ultron\"\n",
    "idx = indices_mapper[movie]\n",
    "print(idx)\n",
    "scores = list(enumerate(cosine_sim[idx]))\n",
    "scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "scores = scores[0:11]\n",
    "idx_ = [s[0] for s in scores]\n",
    "df[\"title\"].iloc[idx_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef31374-6094-4b60-8c54-c0535d51ebfe",
   "metadata": {},
   "source": [
    "Vemos que el recomendador funciona como se esperaba. Vamos a guardar los parámetros y a crear las funciones necesarias para el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be34e401-046d-4081-a1d3-8ec3fe5a7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "MODELS_PATH = os.getenv(\"MODELS_PATH\")\n",
    "os.makedirs(os.path.join(MODELS_PATH, RECOMMENDER_TYPE), exist_ok=True)\n",
    "\n",
    "with open(os.path.join(MODELS_PATH, RECOMMENDER_TYPE, \"tfidf_description_matrix.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(cosine_sim, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fafef5f-90a6-4ff1-a072-2a028dbce056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "DEFAULT_PATH =os.path.join(\n",
    "    os.getenv(\"MODELS_PATH\"),\n",
    "    RECOMMENDER_TYPE,\n",
    "    \"tfidf_description_matrix.pickle\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_param_matrix(path=DEFAULT_PATH):\n",
    "    \"\"\"Carga el modelo basado en descripción de tfidf\n",
    "    Args:\n",
    "        path (str): ruta en la que se encuentra el fichero con los parámetros\n",
    "    Returns:\n",
    "        param_matrix (numpy ndarray): matriz de numpy que contiene la similaridad entre cada película\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        param_matrix = pickle.load(f)\n",
    "    return param_matrix\n",
    "\n",
    "\n",
    "def preprocess_data(dataframe, col=\"description\"):\n",
    "    \"\"\"Pre-procesamiento de los datos previo al entrenamiento.\n",
    "    Args:\n",
    "        dataframe (pandas DataFrame): DataFrame con la columna a procesar\n",
    "        col (str): nombre de la columna sobre la que realizar el procesado. Default description\n",
    "    Returns:\n",
    "        dataframe (pandas DataFrame): datos procesados con nltk\n",
    "    \"\"\"\n",
    "    \n",
    "    stop_w = set(stopwords.words(\"english\"))  # Selecciona los stopwords\n",
    "    \n",
    "    remove_non_alpha_fn = lambda x: re.sub(r\"[^a-zA-Z]\", \" \", x)  # Elimina aquello que no sean palabras\n",
    "    tokenize_fn = lambda x: nltk.tokenize.word_tokenize(x)  # Tokeniza cada entrada\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmer_fn = lambda desc: \" \".join([stemmer.stem(w) for w in desc if w.lower() not in stop_w])  # Paso de estandarización\n",
    "\n",
    "    # Aplica cada función a la columna\n",
    "    for fn in (remove_non_alpha_fn, tokenize_fn, stemmer_fn):\n",
    "        dataframe[col] = dataframe[col].transform(func=fn)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def train_content_recommender(dataframe, preprocess_fn, col=\"description\", count_vec=False):\n",
    "    \"\"\"Entrenamiento del recomendador\n",
    "    Args:\n",
    "        dataframe (pandas DataFrame): DataFrame con los datos para entrenar\n",
    "        preprocess_fn (function): función que realiza el procesado de los datos previo al entrenamiento\n",
    "        col (str): nombre de la columna sobre la que realizar el entrenamiento. Default description\n",
    "        count_vec (bool): booleano que indica si se usa o no CountVectorizer. Default False\n",
    "    Returns:\n",
    "        param_matrix (numpy ndarray): matriz de numpy que contiene la similaridad entre cada película\n",
    "    \"\"\"\n",
    "\n",
    "    if count_vec:\n",
    "        dataframe[col] = dataframe[col].fillna(\"\")\n",
    "        count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0., stop_words=\"english\")\n",
    "        count_vec_matrix = count.fit_transform(processed_data[col])\n",
    "        return cosine_similarity(count_vec_matrix, count_vec_matrix)\n",
    "    processed_data = preprocess_fn(dataframe, col)\n",
    "    tfidf = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 2), stop_words=\"english\", min_df=0.)  # Redundancia de stopwords\n",
    "    tfidf_matrix = tfidf.fit_transform(processed_data[col])\n",
    "\n",
    "    return linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "\n",
    "def get_description_recommendation(movie, top_n= 10, dataframe=df, preprocess_fn=preprocess_data, \n",
    "                                   col=\"description\", count_vec=False, path=DEFAULT_PATH):\n",
    "    \"\"\"Recomendador basado en la descripción de películas\n",
    "    Args:\n",
    "        movie (str): títutlo de la película sobre la que realizará las recomendaciones\n",
    "        top_n (int): número de películas que recomienda al usuario. Default 10\n",
    "        dataframe (pandas DataFrame): DataFrame con los datos para entrenar y los títulos a recomendar\n",
    "        preprocess_fn (function): función que realiza el procesado de los datos previo al entrenamiento\n",
    "        col (str): nombre de la columna sobre la que realizar el entrenamiento en caso de ser necesario. Default description\n",
    "        count_vec (bool): booleano que indica si se usa o no CountVectorizer en el entrenamiento. Default False\n",
    "        path (str): ruta en la que se encuentra el fichero con los parámetros\n",
    "    Returns:\n",
    "        movies list (list): lista con los títulos de las top_n películas más similares\n",
    "    \"\"\"\n",
    "    if not isinstance(movie, str):  # Aseguramos que el usuario introduzca una string y no indicamos que no es tipo str\n",
    "        raise ValueError(\"Película no encontrada.\")\n",
    "\n",
    "    # Intentamos cargar los parámetros. En caso de no haberlos, realizamos el entrenamiento\n",
    "    try:\n",
    "        param_matrix = load_param_matrix(path)\n",
    "    except:\n",
    "        param_matrix = train_content_recommender(df, preprocess_description, col, count_vec)\n",
    "\n",
    "    mapper = pd.Series(dataframe.index, index=dataframe[\"title\"]).drop_duplicates()  # Para mapear ids con títulos\n",
    "    scores = np.argsort(param_matrix[mapper[movie]])[::-1]  # Obtiene los índices de las películas con mayor similaridad\n",
    "    movie_indices = scores[1:top_n + 1] # Top_n películas más similares, eliminando a movie\n",
    "\n",
    "    return list(dataframe[\"title\"].iloc[movie_indices].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab799d0-28f2-4937-8dab-c5eba4693c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tarzan's Greatest Adventure\",\n",
       " 'Iron Man',\n",
       " 'Calculator',\n",
       " 'Iron Man 2',\n",
       " 'A Deadly Adoption',\n",
       " 'Iron Man 3',\n",
       " 'Hawks',\n",
       " 'Fittest On Earth (The Story Of The 2015 Reebok CrossFit Games)',\n",
       " 'Verbo',\n",
       " 'Behind Enemy Lines II: Axis of Evil']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_description_recommendation(\"Avengers: Age of Ultron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18181b63-71a0-4981-b8b1-a090d836a7a6",
   "metadata": {},
   "source": [
    "## Basado en metadatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a700d-cad9-4def-99d5-9aa541aa4dd3",
   "metadata": {},
   "source": [
    "Hemos visto cómo funciona el recomendador basado en la descripción, utilizando el método de Tfidf. Ahora vamos a utilizar la columna que hicimos en el EDA01 para crear un recomendador basado en los metadatos como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad94ce1-865a-49a5-aaf9-00bb1fdbbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"metadata\"] = df[\"metadata\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f432af79-1695-4254-a5aa-5e196ba054a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(analyzer=\"word\", ngram_range=(1, 2), min_df=0., stop_words=\"english\")\n",
    "count_vec_matrix = count_vec.fit_transform(df[\"metadata\"])\n",
    "param_matrix = cosine_similarity(count_vec_matrix, count_vec_matrix)\n",
    "\n",
    "with open(os.path.join(MODELS_PATH, RECOMMENDER_TYPE, \"count_metadata_matrix.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(param_matrix, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c406b306-5b26-4b9d-b0d5-19796ee6ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_mapper = pd.Series(df.index, df[\"title\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd09e1b-876e-427b-921f-658551ff2dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24813                Avengers: Age of Ultron\n",
       "24821             Captain America: Civil War\n",
       "24817                                Ant-Man\n",
       "24819                         Thor: Ragnarok\n",
       "20735                   Thor: The Dark World\n",
       "21714    Captain America: The Winter Soldier\n",
       "19711                             Iron Man 3\n",
       "16633     Captain America: The First Avenger\n",
       "24820         Guardians of the Galaxy Vol. 2\n",
       "14526                             Iron Man 2\n",
       "2486                             Superman II\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = \"Avengers: Age of Ultron\"\n",
    "idx = indices_mapper[movie]\n",
    "print(idx)\n",
    "scores = list(enumerate(param_matrix[idx]))\n",
    "scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "scores = scores[0:11]\n",
    "idx_ = [s[0] for s in scores]\n",
    "df[\"title\"].iloc[idx_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b7c31a4-c194-42f6-8525-fe5e36acfce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain America: Civil War',\n",
       " 'Ant-Man',\n",
       " 'Thor: Ragnarok',\n",
       " 'Thor: The Dark World',\n",
       " 'Captain America: The Winter Soldier',\n",
       " 'Iron Man 3',\n",
       " 'Captain America: The First Avenger',\n",
       " 'Guardians of the Galaxy Vol. 2',\n",
       " 'Iron Man 2',\n",
       " 'Superman II']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_description_recommendation(\"Avengers: Age of Ultron\", col=\"metadatos\", count_vec=True, \n",
    "                               path=os.path.join(os.getenv(\"MODELS_PATH\"), RECOMMENDER_TYPE, \"count_metadata_matrix.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3b752-8bc6-4d08-8af0-965a370ac2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
