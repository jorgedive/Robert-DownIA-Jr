{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c27a238-48b4-4a68-a0a6-c515b6dd363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3425a3e2-3998-4284-8b63-5da9b86c8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "FILENAME = \"cleaned_ratings.csv\"\n",
    "data_path = os.getenv(\"FILES_LOCATION\")\n",
    "RECOMMENDER_TYPE = \"collaborative_filtering\"\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, data_path, \"PNG\", RECOMMENDER_TYPE)\n",
    "os.makedirs(images_path, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, extension=\"png\", resolution=300):  # Función para guardar las figuras que se vayan generando\n",
    "    img_path = os.path.join(IMAGES_PATH, fig_id + \".\" + extension)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(img_path, format=extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486602ad-fabb-427a-a09e-f93d3aef14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Configuración de parámetros de matplotlib\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85db7643-2fae-454f-be56-427c41497cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, \"CSV\", FILENAME), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9813b4-e231-48b2-ba3e-77885e7f7402",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5466bf-b0ef-4e08-9e3d-3ceb16c05da0",
   "metadata": {},
   "source": [
    "El filtro colaborativo es una técnica utilizada para la recomendación de ítems, basada en las valoraciones y otros parámetros como _likes_ que los usuarios dan a los ítems. De esta forma, se realizan recomendaciones basadas en lo que otros usuarios han comprado o han visto. Al igual que en el filtro de contenido lo que hacíamos era computar la similaridad entre metadatos o sinopsis de las películas, en este caso vamos a utilizar la similaridad entre los usuarios, según las valoraciones que han dado a las películas.\n",
    "\n",
    "Antes de nada, vamos a comprobar cuán dispersa es una matriz de usuarios, películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f16d8a7-32cf-461f-8539-9a7ef15a3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.drop(columns=[\"timestamp\"]).sample(frac=1, random_state=42)\n",
    "idx = int(0.9 * len(df_shuffled))\n",
    "df_train = df_shuffled[:idx]\n",
    "df_test = df_shuffled[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c02278-926c-44f3-8662-c5db9ae386e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the new table (32811, 3744)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>162606</th>\n",
       "      <th>163645</th>\n",
       "      <th>164179</th>\n",
       "      <th>164909</th>\n",
       "      <th>166461</th>\n",
       "      <th>166528</th>\n",
       "      <th>166635</th>\n",
       "      <th>166643</th>\n",
       "      <th>168250</th>\n",
       "      <th>168252</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21494</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193942</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "42323       NaN     NaN     NaN     NaN     NaN     4.0     NaN     NaN   \n",
       "21494       3.0     2.0     2.0     NaN     NaN     2.5     2.0     NaN   \n",
       "193942      4.5     4.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  162606  163645  164179  164909  166461  166528  \\\n",
       "userId                   ...                                                   \n",
       "42323       NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "21494       2.0     2.5  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "193942      NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  166635  166643  168250  168252  \n",
       "userId                                   \n",
       "42323       NaN     NaN     NaN     NaN  \n",
       "21494       NaN     NaN     NaN     NaN  \n",
       "193942      NaN     NaN     NaN     NaN  \n",
       "\n",
       "[3 rows x 3744 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = df_train.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "print(f\"Shape of the new table {(df_pivot.shape)}\")\n",
    "df_pivot.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6b967-b0bf-47c7-b9d1-7da262003c19",
   "metadata": {},
   "source": [
    "Nuestra matriz es demasiado dispersa, por lo que utilizaremos el _DataFrame_ importado directamente del CSV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437608f-1b04-42fc-9d86-37473290623d",
   "metadata": {},
   "source": [
    "## Descomposición Matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9262b7-3fbb-49bc-8314-6e86e863217c",
   "metadata": {},
   "source": [
    "Vamos a factorizar nuestro _dataset_ matricial en un producto de matrices: una matriz de usuarios y una matriz de items (películas en nuestro caso). Cada matriz contendrá parámetros asociados a cada película y cada usuario, como si hiciésemos una regresión lineal por película y usuario. Para entrenar este modelo, utilizaremos el método de descenso de gradiente para que el algoritmo encuentre las variables latentes que representen las matrices descompuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e262306f-127e-4a66-b19b-11f3621b234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = {usr_id: i for i, usr_id in enumerate(df_train[\"userId\"].unique())}\n",
    "movie_mapper = {mov_id: i for i, mov_id in enumerate(df_train[\"movieId\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec38b0da-de66-474e-bdc1-d7ce7ef8ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train, user_test = df_train[\"userId\"].map(user_mapper), df_test[\"userId\"].map(user_mapper)\n",
    "movie_train, movie_test = df_train[\"movieId\"].map(movie_mapper), df_test[\"movieId\"].map(movie_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5234682-556c-476b-afa3-7967983b7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = len(user_mapper)\n",
    "movie_emb = len(movie_mapper)\n",
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "609dd4e9-05c6-49f8-8c93-3089550a5540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m170982/170982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 2ms/step - loss: 2.9657 - val_loss: 0.7255\n",
      "Epoch 2/5\n",
      "\u001b[1m170982/170982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2ms/step - loss: 0.6964 - val_loss: 0.6555\n",
      "Epoch 3/5\n",
      "\u001b[1m170982/170982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 2ms/step - loss: 0.6369 - val_loss: 0.6277\n",
      "Epoch 4/5\n",
      "\u001b[1m170982/170982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 3ms/step - loss: 0.6096 - val_loss: 0.6185\n",
      "Epoch 5/5\n",
      "\u001b[1m170982/170982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 3ms/step - loss: 0.5985 - val_loss: 0.6156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x385041bd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user_in\")\n",
    "movie_input = tf.keras.layers.Input(shape=(1,), name=\"movie_in\")\n",
    "\n",
    "user_embeddings = tf.keras.layers.Embedding(output_dim=embedding_dim,\n",
    "                                           input_dim=user_emb,\n",
    "                                           input_length=1,\n",
    "                                           name=\"user_embedding_layer\")(user_input)\n",
    "\n",
    "movie_embeddings = tf.keras.layers.Embedding(output_dim=embedding_dim,\n",
    "                                             input_dim=movie_emb,\n",
    "                                             input_length=1,\n",
    "                                             name=\"movie_embedding_layer\")(movie_input)\n",
    "\n",
    "user_vector = tf.keras.layers.Reshape([embedding_dim])(user_embeddings)\n",
    "movie_vector = tf.keras.layers.Reshape([embedding_dim])(movie_embeddings)\n",
    "\n",
    "y = tf.keras.layers.Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, movie_input], outputs=y)\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model.fit([user_train, movie_train],\n",
    "          df_train[\"rating\"],\n",
    "          batch_size=64, \n",
    "          epochs=5,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1de871c9-3aa1-42fc-bb6a-4dd92021981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42218/42218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 513us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict([user_test, movie_test])\n",
    "y_true = df_test[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3481f5a0-963e-46ee-994c-88ab1d8c05f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Matrix Factorization RMSE: 0.78386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_hat, y_true))\n",
    "print(f\"Keras Matrix Factorization RMSE: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eafb9862-554f-4280-b052-93f8289e8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/6s8r8xv94g19lwr4cfdxhjdm0000gn/T/ipykernel_86117/1783250639.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"predicted\"] = y_hat.ravel()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10095257</th>\n",
       "      <td>201586</td>\n",
       "      <td>1965</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.589502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996409</th>\n",
       "      <td>160408</td>\n",
       "      <td>119145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.098611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727963</th>\n",
       "      <td>54035</td>\n",
       "      <td>4270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.177845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10435292</th>\n",
       "      <td>208773</td>\n",
       "      <td>7361</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.139297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10794283</th>\n",
       "      <td>215723</td>\n",
       "      <td>8961</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.070157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating  predicted\n",
       "10095257  201586     1965     3.0   3.589502\n",
       "7996409   160408   119145     2.0   3.098611\n",
       "2727963    54035     4270     3.0   2.177845\n",
       "10435292  208773     7361     3.5   4.139297\n",
       "10794283  215723     8961     5.0   5.070157"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"predicted\"] = y_hat.ravel()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ee25c11-c91c-4973-ba5d-7cec84c6ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.getenv(\"MODELS_PATH\")\n",
    "collaborative_path = os.path.join(models_path, \"collaborative_filtering\")\n",
    "if not os.path.exists(collaborative_path):\n",
    "    os.mkdir(collaborative_path)\n",
    "model.save(os.path.join(collaborative_path, \"collaborative_matrix_decomposition.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c08cb-7f89-4880-bda0-44a2162711bb",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db7e06-ff5a-464e-ac62-b6756f92f380",
   "metadata": {},
   "source": [
    "Otra forma de crear un recomendador de filtro colaborativo es tener dos redes neuronales: una para usuario y otra para items; minimizando una función de coste que nos permita medir la distancia entre los vectores codificados de cada red (típicamente la norma $L_{2}$). También puede realizarse algo similar a lo que hicimos en el apartado anterior, pasar los usuarios y películas por capas separadas de Embedding y concatenar las salidas para llevarlas a una red neuronal común. Debido a que el volumen de datos es relativamente grande, vamos a utilizar el segundo acercamiento, ya que tardará menos en ser entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf2d0671-2617-4a74-8c25-c5d5a18d52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 4ms/step - loss: 0.7626 - val_loss: 0.6407\n",
      "Epoch 2/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 4ms/step - loss: 0.6219 - val_loss: 0.6105\n",
      "Epoch 3/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 4ms/step - loss: 0.5869 - val_loss: 0.5886\n",
      "Epoch 4/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 4ms/step - loss: 0.5632 - val_loss: 0.5761\n",
      "Epoch 5/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 4ms/step - loss: 0.5466 - val_loss: 0.5695\n",
      "Epoch 6/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 4ms/step - loss: 0.5363 - val_loss: 0.5662\n",
      "Epoch 7/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 4ms/step - loss: 0.5277 - val_loss: 0.5640\n",
      "Epoch 8/8\n",
      "\u001b[1m85491/85491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 4ms/step - loss: 0.5217 - val_loss: 0.5630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x44d459450>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb_dim = 20\n",
    "movie_emb_dim = 20\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user_in\")\n",
    "movie_input = tf.keras.layers.Input(shape=(1,), name=\"movie_in\")\n",
    "\n",
    "\n",
    "user_embeddings = tf.keras.layers.Embedding(output_dim=user_emb_dim, \n",
    "                           input_dim=user_emb,\n",
    "                           input_length=1, \n",
    "                           name=\"user_embedding\")(user_input)\n",
    "\n",
    "movie_embeddings = tf.keras.layers.Embedding(output_dim=movie_emb_dim, \n",
    "                            input_dim=movie_emb,\n",
    "                            input_length=1, \n",
    "                            name=\"movie_embedding\")(movie_input)\n",
    "\n",
    "\n",
    "user_vector = tf.keras.layers.Reshape([user_emb_dim])(user_embeddings)\n",
    "movie_vector = tf.keras.layers.Reshape([movie_emb_dim])(movie_embeddings)\n",
    "concat = tf.keras.layers.Concatenate()([user_vector, movie_vector])\n",
    "\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\")(concat)\n",
    "dense2 = tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\")(dense1)\n",
    "y = tf.keras.layers.Dense(units=1, activation=\"linear\")(dense2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, movie_input], outputs=y)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "model.fit([user_train, movie_train],\n",
    "          df_train[\"rating\"],\n",
    "          batch_size=128, \n",
    "          epochs=8,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51a3c5bf-e55f-453e-8451-77ea9b8a9927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42218/42218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 289us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict([user_test, movie_test])\n",
    "y_true = df_test[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "964d424f-7aeb-4c4e-887b-984edf256c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning RMSE: 0.74991\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_hat, y_true))\n",
    "print(f\"Deep Learning RMSE: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7db14b2-6cbd-4dee-8c7f-29a9248b8c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/6s8r8xv94g19lwr4cfdxhjdm0000gn/T/ipykernel_86117/2916800581.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"predicted_deep\"] = y_hat.ravel()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_deep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10095257</th>\n",
       "      <td>201586</td>\n",
       "      <td>1965</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.589502</td>\n",
       "      <td>3.562252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996409</th>\n",
       "      <td>160408</td>\n",
       "      <td>119145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.098611</td>\n",
       "      <td>3.508584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727963</th>\n",
       "      <td>54035</td>\n",
       "      <td>4270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.177845</td>\n",
       "      <td>2.304413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10435292</th>\n",
       "      <td>208773</td>\n",
       "      <td>7361</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.139297</td>\n",
       "      <td>4.145404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10794283</th>\n",
       "      <td>215723</td>\n",
       "      <td>8961</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.070157</td>\n",
       "      <td>4.698391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating  predicted  predicted_deep\n",
       "10095257  201586     1965     3.0   3.589502        3.562252\n",
       "7996409   160408   119145     2.0   3.098611        3.508584\n",
       "2727963    54035     4270     3.0   2.177845        2.304413\n",
       "10435292  208773     7361     3.5   4.139297        4.145404\n",
       "10794283  215723     8961     5.0   5.070157        4.698391"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"predicted_deep\"] = y_hat.ravel()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3c4e1a4-e334-462e-92d7-7c5b30843a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(collaborative_path, \"collaborative_deep_learning.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09a1ce-79a6-4e28-87fd-b9844031d458",
   "metadata": {},
   "source": [
    "En este _notebook_ hemos visto cómo realizar un sistema recomendador basado en el filtro colaborativo. Este sistema podría combinarse con uno basado en contenido para tener un recomendador híbrido. En un entorno de producción, este sistema colaborativo recomendaría a un nuevo usuario películas basadas en las valoraciones medias y a medida que el usuario consumiese películas, se las recomendaría en base a la similaridad con otros usuarios. \n",
    "\n",
    "En el filtro colaborativo, a parte de las valoraciones de los usuarios, podríamos realizar recomendaciones basadas en las valoraciones y la puntuación asociada a cada género de la película. Esta puntuación asociada al género podría inferirse con un algoritmo de filtro colaborativo como el que hemos realizado en este _notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7a732-6e93-4fb3-9422-186bea533e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
