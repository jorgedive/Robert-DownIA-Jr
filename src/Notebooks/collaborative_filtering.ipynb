{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c27a238-48b4-4a68-a0a6-c515b6dd363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3425a3e2-3998-4284-8b63-5da9b86c8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "data_path = os.getenv(\"FILES_PATH\")\n",
    "images_path = os.path.join(data_path, \"PNG\", \"collaborative_filtering\")\n",
    "os.makedirs(images_path, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, extension=\"png\", resolution=300):  # Función para guardar las figuras que se vayan generando\n",
    "    img_path = os.path.join(IMAGES_PATH, fig_id + \".\" + extension)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(img_path, format=extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486602ad-fabb-427a-a09e-f93d3aef14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Configuración de parámetros de matplotlib\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85db7643-2fae-454f-be56-427c41497cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, \"CSV\", \"cleaned_ratings.csv\"), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9813b4-e231-48b2-ba3e-77885e7f7402",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5466bf-b0ef-4e08-9e3d-3ceb16c05da0",
   "metadata": {},
   "source": [
    "El filtro colaborativo es una técnica utilizada para la recomendación de ítems, basada en las valoraciones y otros parámetros como _likes_ que los usuarios dan a los ítems. De esta forma, se realizan recomendaciones basadas en lo que otros usuarios han comprado o han visto. Al igual que en el filtro de contenido lo que hacíamos era computar la similaridad entre metadatos o sinopsis de las películas, en este caso vamos a utilizar la similaridad entre los usuarios, según las valoraciones que han dado a las películas.\n",
    "\n",
    "Antes de nada, vamos a comprobar cuán dispersa es una matriz de usuarios, películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f16d8a7-32cf-461f-8539-9a7ef15a3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.drop(columns=[\"timestamp\"]).sample(frac=1, random_state=42)\n",
    "idx = int(0.9 * len(df_shuffled))\n",
    "df_train = df_shuffled[:idx]\n",
    "df_test = df_shuffled[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c02278-926c-44f3-8662-c5db9ae386e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/bntb_6c1617cvy8kh1mz_mnw0000gn/T/ipykernel_3627/2304156484.py:1: PerformanceWarning: The following operation may generate 11966947627 cells in the resulting pandas object.\n",
      "  df_pivot = df_train.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mpivot_table(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m\"\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m\"\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the new table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(df_pivot\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_pivot\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9509\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   9492\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9493\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   9494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot_table\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9505\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   9506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9507\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot_table\n\u001b[0;32m-> 9509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pivot_table(\n\u001b[1;32m   9510\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9511\u001b[0m         values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m   9512\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   9513\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   9514\u001b[0m         aggfunc\u001b[38;5;241m=\u001b[39maggfunc,\n\u001b[1;32m   9515\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   9516\u001b[0m         margins\u001b[38;5;241m=\u001b[39mmargins,\n\u001b[1;32m   9517\u001b[0m         dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   9518\u001b[0m         margins_name\u001b[38;5;241m=\u001b[39mmargins_name,\n\u001b[1;32m   9519\u001b[0m         observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[1;32m   9520\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m   9521\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:102\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     99\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m table \u001b[38;5;241m=\u001b[39m __internal_pivot_table(\n\u001b[1;32m    103\u001b[0m     data,\n\u001b[1;32m    104\u001b[0m     values,\n\u001b[1;32m    105\u001b[0m     index,\n\u001b[1;32m    106\u001b[0m     columns,\n\u001b[1;32m    107\u001b[0m     aggfunc,\n\u001b[1;32m    108\u001b[0m     fill_value,\n\u001b[1;32m    109\u001b[0m     margins,\n\u001b[1;32m    110\u001b[0m     dropna,\n\u001b[1;32m    111\u001b[0m     margins_name,\n\u001b[1;32m    112\u001b[0m     observed,\n\u001b[1;32m    113\u001b[0m     sort,\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/pivot.py:219\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    216\u001b[0m         table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mreindex(m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39mfill_value)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(table, ABCDataFrame):\n\u001b[0;32m--> 219\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39msort_index(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfillna(fill_value)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:7379\u001b[0m, in \u001b[0;36mDataFrame.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   7282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msort_index\u001b[39m(\n\u001b[1;32m   7283\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   7284\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7293\u001b[0m     key: IndexKeyFunc \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   7294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   7295\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7296\u001b[0m \u001b[38;5;124;03m    Sort object by labels (along an axis).\u001b[39;00m\n\u001b[1;32m   7297\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7377\u001b[0m \u001b[38;5;124;03m    d  4\u001b[39;00m\n\u001b[1;32m   7378\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 7379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msort_index(\n\u001b[1;32m   7380\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   7381\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   7382\u001b[0m         ascending\u001b[38;5;241m=\u001b[39mascending,\n\u001b[1;32m   7383\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   7384\u001b[0m         kind\u001b[38;5;241m=\u001b[39mkind,\n\u001b[1;32m   7385\u001b[0m         na_position\u001b[38;5;241m=\u001b[39mna_position,\n\u001b[1;32m   7386\u001b[0m         sort_remaining\u001b[38;5;241m=\u001b[39msort_remaining,\n\u001b[1;32m   7387\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m   7388\u001b[0m         key\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m   7389\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5317\u001b[0m, in \u001b[0;36mNDFrame.sort_index\u001b[0;34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[0m\n\u001b[1;32m   5315\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   5316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5317\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   5319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   5320\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[1;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6815\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[1;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_pivot = df_train.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "print(f\"Shape of the new table {(df_pivot.shape)}\")\n",
    "df_pivot.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6b967-b0bf-47c7-b9d1-7da262003c19",
   "metadata": {},
   "source": [
    "Nuestra matriz es demasiado dispersa, por lo que utilizaremos el _DataFrame_ importado directamente del CSV. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437608f-1b04-42fc-9d86-37473290623d",
   "metadata": {},
   "source": [
    "## Descomposición Matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9262b7-3fbb-49bc-8314-6e86e863217c",
   "metadata": {},
   "source": [
    "Vamos a factorizar nuestro _dataset_ matricial en un producto de matrices: una matriz de usuarios y una matriz de items (películas en nuestro caso). Cada matriz contendrá parámetros asociados a cada película y cada usuario, como si hiciésemos una regresión lineal por película y usuario. Para entrenar este modelo, utilizaremos el método de descenso de gradiente para que el algoritmo encuentre las variables latentes que representen las matrices descompuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262306f-127e-4a66-b19b-11f3621b234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = {usr_id: i for i, usr_id in enumerate(df_train[\"userId\"].unique())}\n",
    "movie_mapper = {mov_id: i for i, mov_id in enumerate(df_train[\"movieId\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38b0da-de66-474e-bdc1-d7ce7ef8ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train, user_test = df_train[\"userId\"].map(user_mapper), df_test[\"userId\"].map(user_mapper)\n",
    "movie_train, movie_test = df_train[\"movieId\"].map(movie_mapper), df_test[\"movieId\"].map(movie_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234682-556c-476b-afa3-7967983b7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = len(user_mapper)\n",
    "movie_emb = len(movie_mapper)\n",
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609dd4e9-05c6-49f8-8c93-3089550a5540",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user_in\")\n",
    "movie_input = tf.keras.layers.Input(shape=(1,), name=\"movie_in\")\n",
    "\n",
    "user_embeddings = tf.keras.layers.Embedding(output_dim=embedding_dim,\n",
    "                                           input_dim=user_emb,\n",
    "                                           input_length=1,\n",
    "                                           name=\"user_embedding_layer\")(user_input)\n",
    "\n",
    "movie_embeddings = tf.keras.layers.Embedding(output_dim=embedding_dim,\n",
    "                                             input_dim=movie_emb,\n",
    "                                             input_length=1,\n",
    "                                             name=\"movie_embedding_layer\")(movie_input)\n",
    "\n",
    "user_vector = tf.keras.layers.Reshape([embedding_dim])(user_embeddings)\n",
    "movie_vector = tf.keras.layers.Reshape([embedding_dim])(movie_embeddings)\n",
    "\n",
    "y = tf.keras.layers.Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, movie_input], outputs=y)\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "model.fit([user_train, movie_train],\n",
    "          df_train[\"rating\"],\n",
    "          batch_size=64, \n",
    "          epochs=5,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de871c9-3aa1-42fc-bb6a-4dd92021981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict([user_test, movie_test])\n",
    "y_true = df_test[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481f5a0-963e-46ee-994c-88ab1d8c05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_hat, y_true))\n",
    "print(f\"Keras Matrix Factorization RMSE: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb9862-554f-4280-b052-93f8289e8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"predicted\"] = y_hat.ravel()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee25c11-c91c-4973-ba5d-7cec84c6ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(data_path, \"models\")\n",
    "collaborative_path = os.path.join(models_path, \"collaborative_filtering\")\n",
    "if not os.path.exists(collaborative_path):\n",
    "    os.mkdir(collaborative_path)\n",
    "model.save(os.path.join(collaborative_path, \"collaborative_matrix_decomposition.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c08cb-7f89-4880-bda0-44a2162711bb",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db7e06-ff5a-464e-ac62-b6756f92f380",
   "metadata": {},
   "source": [
    "Otra forma de crear un recomendador de filtro colaborativo es tener dos redes neuronales: una para usuario y otra para items; minimizando una función de coste que nos permita medir la distancia entre los vectores codificados de cada red (típicamente la norma $L_{2}$). También puede realizarse algo similar a lo que hicimos en el apartado anterior, pasar los usuarios y películas por capas separadas de Embedding y concatenar las salidas para llevarlas a una red neuronal común. Debido a que el volumen de datos es relativamente grande, vamos a utilizar el segundo acercamiento, ya que tardará menos en ser entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d0671-2617-4a74-8c25-c5d5a18d52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb_dim = 20\n",
    "movie_emb_dim = 20\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=(1,), name=\"user_in\")\n",
    "movie_input = tf.keras.layers.Input(shape=(1,), name=\"movie_in\")\n",
    "\n",
    "\n",
    "user_embeddings = tf.keras.layers.Embedding(output_dim=user_emb_dim, \n",
    "                           input_dim=user_emb,\n",
    "                           input_length=1, \n",
    "                           name=\"user_embedding\")(user_input)\n",
    "\n",
    "movie_embeddings = tf.keras.layers.Embedding(output_dim=movie_emb_dim, \n",
    "                            input_dim=movie_emb,\n",
    "                            input_length=1, \n",
    "                            name=\"movie_embedding\")(movie_input)\n",
    "\n",
    "\n",
    "user_vector = tf.keras.layers.Reshape([user_emb_dim])(user_embeddings)\n",
    "movie_vector = tf.keras.layers.Reshape([movie_emb_dim])(movie_embeddings)\n",
    "concat = tf.keras.layers.Concatenate()([user_vector, movie_vector])\n",
    "\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\")(concat)\n",
    "dense2 = tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\")(dense1)\n",
    "y = tf.keras.layers.Dense(units=1, activation=\"linear\")(dense2)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[user_input, movie_input], outputs=y)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "model.fit([user_train, movie_train],\n",
    "          df_train[\"rating\"],\n",
    "          batch_size=128, \n",
    "          epochs=8,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3c5bf-e55f-453e-8451-77ea9b8a9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict([user_test, movie_test])\n",
    "y_true = df_test[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d424f-7aeb-4c4e-887b-984edf256c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_hat, y_true))\n",
    "print(f\"Deep Learning RMSE: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db14b2-6cbd-4dee-8c7f-29a9248b8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"predicted_deep\"] = y_hat.ravel()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4e1a4-e334-462e-92d7-7c5b30843a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(collaborative_path, \"collaborative_deep_learning.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09a1ce-79a6-4e28-87fd-b9844031d458",
   "metadata": {},
   "source": [
    "En este _notebook_ hemos visto cómo realizar un sistema recomendador basado en el filtro colaborativo. Este sistema podría combinarse con uno basado en contenido para tener un recomendador híbrido. En un entorno de producción, este sistema colaborativo recomendaría a un nuevo usuario películas basadas en las valoraciones medias y a medida que el usuario consumiese películas, se las recomendaría en base a la similaridad con otros usuarios. \n",
    "\n",
    "En el filtro colaborativo, a parte de las valoraciones de los usuarios, podríamos realizar recomendaciones basadas en las valoraciones y la puntuación asociada a cada género de la película. Esta puntuación asociada al género podría inferirse con un algoritmo de filtro colaborativo como el que hemos realizado en este _notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7a732-6e93-4fb3-9422-186bea533e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
